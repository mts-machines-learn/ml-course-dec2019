{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План занятия:\n",
    "\n",
    "1. Применение линейной регрессии на реальных данных\n",
    "2. Нормализация данных\n",
    "3. Полиномиальная регрессия\n",
    "4. Переобучение и недообучение\n",
    "5. Средняя абсолютная функция ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from regression2_helper import * # Подгружаем функции для визуализации\n",
    "import numpy as np              # Подгруджаем библиотеку NumPy\n",
    "np.set_printoptions(formatter={'float': lambda x: format(x, '6.3f')}) # настройка вывода для матриц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение линейной регрессии на реальных данных\n",
    "\n",
    "Рассмотрим реальный датасет содержащий данные о стоимости жилья в Бостоне.  \n",
    "Данные были собраны в 1978 году и содержат 506 записей, представляющие собой 14 агрегированных характеристик домов из пригородов Бостона, штат Массачусетс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **CRIM**: Уровень преступности  \n",
    "2. **ZN**: Доля жилой земли, отведенной под участки более 25000 кв. Футов  \n",
    "3. **INDUS**: Доля неторговых площадей на город  \n",
    "4. **CHAS**: Фиктивная переменная реки Чарльз (= 1, если путь ограничивает реку; 0 в противном случае)  \n",
    "5. **NOX**: Концентрация оксида азота  \n",
    "6. **RM**: Среднее количество комнат в доме  \n",
    "7. **AGE**: Доля домов, построенных до 1940 года  \n",
    "8. **DIS**: Взвешенные расстояния до пяти бостонских центров занятости  \n",
    "9. **RAD**: Индекс доступности к радиальным магистралям  \n",
    "10. **TAX**: Ставка налога на полную стоимость имущества за 10000 долларов США  \n",
    "11. **PTRATIO**: Соотношение учеников и учителей по городам   \n",
    "12. **B**: $1000(Bk - 0,63)^2$, где $Bk$ - это доля людей афроамериканского происхождения по городам  \n",
    "13. **LSTAT**: процент населения с более низким статусом чем у жильца  \n",
    "14. **MEDV**: медианная цена за дом с такими параметрами в 1000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша задача будет предсказать цену домов (MEDV) используя данные характеристики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия на двух параметрах "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала построим модель линейной регрессии для предсказания медианной цены домов,   \n",
    "используя всего два признака: RM и LSTAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#загрузим данные\n",
    "X_room, X_lstat, y = load_small_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_3d_table_with_data(X_room, X_lstat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим зависимости каждого из признаков с ценой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_rm(X_room, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_lstat(X_lstat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим теперь зависимость от двух признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_new_3d_data(X_room, X_lstat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция от двух параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для предсказания цен квартир в Бостоне по данной паре признаков, рассмотрим модель линейной регрессию вида:\n",
    "\\begin{equation*}\n",
    "\\tilde{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2.\n",
    "\\end{equation*}\n",
    "$\\tilde{y}$ - предсказанная цена  \n",
    "$x_1$ - Cреднее количество комнат  \n",
    "$x_2$ - LSTAT %  \n",
    "$\\theta_0, \\theta_1, \\theta_2$ - параметры модели (веса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем как выглядит эта функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_new_3d_data_and_hyp(X_room, X_lstat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная функция в матричном виде"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте вспомним как производить матричное произведение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "A = \\begin{pmatrix}\n",
    "    a_{0, 0} & a_{0, 1} & \\ldots & a_{0, j} \\ldots a_{0, m} \\\\\n",
    "    a_{1, 0} & a_{1, 1} & \\ldots & a_{1, j} \\ldots a_{1, m} \\\\\n",
    "    \\cdot &   \\cdot  & \\cdot &    \\cdot \\\\\n",
    "    a_{i, 0} & a_{i, 1} & \\ldots & a_{i, j} \\ldots a_{i, m} \\\\\n",
    "    \\cdot &   \\cdot  & \\cdot &    \\cdot \\\\\n",
    "    a_{n, 0} & a_{N, 1} & \\ldots & a_{n, j} \\ldots a_{n, m} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Размер $A = (n, m)$.\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "X = \\begin{pmatrix}\n",
    "    x_{0, 0} & x_{0, 1} & \\ldots & x_{0, j} \\ldots x_{0, k} \\\\\n",
    "    x_{1, 0} & x_{1, 1} & \\ldots & x_{1, j} \\ldots x_{1, k} \\\\\n",
    "    \\cdot &   \\cdot  & \\cdot &    \\cdot \\\\\n",
    "    x_{i, 0} & x_{i, 1} & \\ldots & x_{i, j} \\ldots x_{i, k} \\\\\n",
    "    \\cdot &   \\cdot  & \\cdot &    \\cdot \\\\\n",
    "    x_{m, 0} & x_{m, 1} & \\ldots & x_{m, j} \\ldots x_{m, k} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Размер $X = (m, k)$.\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "Y = A \\cdot X= \\begin{pmatrix}\n",
    "    \\sum_i^m a_{0, i}x_{i, 0} & \\ldots & \\sum_i^m a_{0, i}x_{i, j} & \\ldots & \\sum_i^m a_{0, i}x_{i, k} \\\\\n",
    "    \\sum_i^m a_{1, i}x_{i, 1} & \\ldots & \\sum_i^m a_{1, i}x_{i, j} & \\ldots & \\sum_i^m a_{1, i}x_{i, k} \\\\\n",
    "    \\cdot &   \\cdot  & \\cdot &    \\cdot \\\\\n",
    "    \\sum_i^m a_{k, i}x_{i, k} & \\ldots & \\sum_i^m a_{k, i}x_{i, j} & \\ldots & \\sum_i^m a_{k, i}x_{i, k} \\\\\n",
    "    \\cdot &   \\cdot  & \\cdot &    \\cdot \\\\\n",
    "    \\sum_i^m a_{n, i}x_{i, n} & \\ldots & \\sum_i^m a_{n, i}x_{i, j} & \\ldots & \\sum_i^m a_{n, i}x_{i, k} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Размер $Y = (n, k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И отдельно рассмотрим произведение матрицы и вектора строки на вектор колонку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Произведение векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "z = \\begin{pmatrix}\n",
    "    z_{0, 0} & z_{0, 1} & \\ldots & z_{0, j} \\ldots z_{0, m} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "v = \\begin{pmatrix}\n",
    "    v_{0, 0} \\\\\n",
    "    v_{1, 0} \\\\\n",
    "    \\ldots \\\\\n",
    "    v_{j, 0} \\\\\n",
    "    \\ldots \\\\\n",
    "    v_{m, 0}\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Часто для удобства $v$ записывают как \\begin{equation*}\n",
    "v = \\begin{pmatrix}\n",
    "    v_{0, 0} &\n",
    "    v_{1, 0} &\n",
    "    \\ldots &\n",
    "    v_{j, 0} &\n",
    "    \\ldots &\n",
    "    v_{m, 0}\n",
    "\\end{pmatrix}^T\n",
    "\\end{equation*}\n",
    "\n",
    "$z v = \\sum_i^m z_{0, i}v_{i, 0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Произведение матрицу на вектор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "A \\cdot v = \\begin{pmatrix}\n",
    "    a_{0, 0} & a_{0, 1} & \\ldots & a_{0, j} \\ldots a_{0, m} \\\\\n",
    "    a_{1, 0} & a_{1, 1} & \\ldots & a_{1, j} \\ldots a_{1, m} \\\\\n",
    "    \\cdot &   \\cdot  & \\cdot &    \\cdot \\\\\n",
    "    a_{i, 0} & a_{i, 1} & \\ldots & a_{i, j} \\ldots a_{i, m} \\\\\n",
    "    \\cdot &   \\cdot  & \\cdot &    \\cdot \\\\\n",
    "    a_{n, 0} & a_{N, 1} & \\ldots & a_{n, j} \\ldots a_{n, m} \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "    v_{0, 0} \\\\\n",
    "    v_{1, 0} \\\\\n",
    "    \\ldots \\\\\n",
    "    v_{j, 0} \\\\\n",
    "    \\ldots \\\\\n",
    "    v_{m, 0}\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "A \\cdot v = \\begin{pmatrix}\n",
    "    a_{0, 0}v_{0, 0} + a_{0, 1}v_{1, 0} + \\ldots + a_{0, j}v_{j, 0} + \\ldots +a_{0, m}v_{m, 0} \\\\\n",
    "    a_{1, 0}v_{0, 0} + a_{1, 1}v_{1, 0} + \\ldots + a_{2, j}v_{j, 0} + \\ldots +a_{2, m}v_{m, 0} \\\\\n",
    "    \\cdots \\\\\n",
    "    a_{i, 0}v_{0, 0} + a_{i, 1}v_{1, 0} + \\ldots + a_{i, j}v_{j, 0} + \\ldots +a_{i, m}v_{m, 0} \\\\\n",
    "    \\cdots \\\\\n",
    "    a_{n, 0}v_{0, 0} + a_{n, 1}v_{1, 0} + \\ldots + a_{n, j}v_{j, 0} + \\ldots +a_{n, m}v_{m, 0} \\\\\n",
    "\\end{pmatrix} =\n",
    "\\begin{pmatrix}\n",
    "    \\sum_i^m a_{0, i}v_{i, 0} \\\\\n",
    "    \\sum_i^m a_{1, i}v_{i, 0} \\\\\n",
    "    \\cdots \\\\\n",
    "    \\sum_i^m a_{j, i}v_{i, 0} \\\\\n",
    "    \\cdots \\\\\n",
    "    \\sum_i^m a_{n, i}v_{i, 0} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как это можно использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте объединим признаки для $i$-того примера в вектор стоку \n",
    "\\begin{equation*}\n",
    "x_i = \\begin{pmatrix} x_{i, 1} & x_{i, 2}\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "$x_{i, 1}$ - это среднее количество комнат $i$-го примера.\n",
    "\n",
    "$x_{i, 2}$ - LSTAT $i$-го примера.\n",
    "\n",
    "Давайте также объединим коэффициенты в вектор столбец $\\theta = \\begin{pmatrix}\n",
    "    \\theta_1\\\\\n",
    "    \\theta_2\\\\\n",
    "  \\end{pmatrix} =  \\begin{pmatrix}\\theta_1 & \\theta_2 \\end{pmatrix}^T$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединив признаки и коэффициенты в вектора можем переписать предсказание $i$-того примера в матричном виде:\n",
    "  \\begin{equation*}\n",
    "\\tilde{y_i}= \\theta_0 + \\begin{pmatrix}x_{i, 1} & x_{i, 2}\\end{pmatrix} \\begin{pmatrix}\n",
    "    \\theta_1\\\\\n",
    "    \\theta_2\\\\\n",
    "  \\end{pmatrix} = \\theta_0 + \\theta_1 x_{i, 1} + \\theta_2 x_{i, 2}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или переписав использовав матричное умножение:\n",
    "$\\tilde{y}= \\theta_0 + x_i \\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы избавиться от свободного члена $\\theta_0$  и записать выражение полностью в матричном виде, сделаем следующий трюк: добавим к вектору $x_i$  единицу:\n",
    "\n",
    "${X}_i = \\begin{pmatrix} 1 & x_{i, 1} & x_{i, 2}\\end{pmatrix}$\n",
    "\n",
    "Тогда $\\theta_0$ можно добавить в вектор столбец $\\theta$ первым элементом:\n",
    "\\begin{equation*}\n",
    "\\Theta = \\begin{pmatrix}\\theta_0 &  \\theta_1 & \\theta_2\\end{pmatrix}^T,\n",
    "\\end{equation*}\n",
    "\n",
    "а вычисление предсказанной цены $\\tilde{y}_i$ сведется всего лишь к матричному произведению:\n",
    "  \\begin{equation*}\n",
    "\\tilde{y}_i= \\begin{pmatrix} 1 & x_{i, 1} & x_{i, 2}\\end{pmatrix} \\begin{pmatrix}\n",
    "    \\theta_0\\\\\n",
    "    \\theta_1\\\\\n",
    "    \\theta_2\\\\\n",
    "  \\end{pmatrix} =  1 \\cdot \\theta_0 + \\theta_1 x_{i, 1} + \\theta_2 x_{i, 2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\tilde{y}_i = X_i\\Theta.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта формула позволяет вычислить предсказание для одного конкретного жилья в Бостоне.\n",
    "\n",
    "Плюсом матричного произведение является то, что мы можем вычислить предсказание стоимости жилья сразу для всех квартир."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим у нас есть $N$ примеров в обучающей выборке. $x_{i,0} = 1$. Тогда весь набор можно записать как:\n",
    "\n",
    "\\begin{equation*}\n",
    "X= \\begin{pmatrix}\n",
    "1& x_{1,1}& x_{1,2} \\\\\n",
    "1& x_{2,1}& x_{2,2} \\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "1& x_{i,1}& x_{i,2} \\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "1& x_{N,1}& x_{N,2} \\\\\n",
    "\\end{pmatrix}=\n",
    "\\begin{pmatrix}\n",
    "x_{1,0}& x_{1,1}& x_{1,2} \\\\\n",
    "x_{2,0}& x_{2,1}& x_{2,2} \\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "x_{i,0}& x_{i,1}& x_{i,2} \\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "x_{N,0}& x_{N,1}& x_{N,2} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "или\n",
    "\n",
    "\\begin{equation*}\n",
    "X= \\begin{pmatrix}\n",
    "X_0 \\\\\n",
    "X_1 \\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "X_i \\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "X_N \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Или в самом коротком виде: $X = \\begin{pmatrix} X_1 & X_2 & \\ldots & X_N \\end{pmatrix}^T$, где $X_i = \\begin{pmatrix} x_{i,0} & x_{i,1} & x_{i,2}\\end{pmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Тогда для предсказания стоимости жилья всех квартир, запишим $N$ выражений:\n",
    "\n",
    "\n",
    "\\begin{cases}\n",
    "\\tilde{y}_1 = 1\\cdot \\theta_0 + \\theta_1 x_{1,1} + \\theta_2 x_{1,2}\\\\\n",
    "\\tilde{y}_2 = 1\\cdot \\theta_0 + \\theta_1 x_{2,1} + \\theta_2 x_{2,2}\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "\\tilde{y}_i = 1\\cdot \\theta_0 + \\theta_1 x_{i,1} + \\theta_2 x_{i,2}\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "\\tilde{y}_N = 1\\cdot \\theta_0 + \\theta_1 x_{N,1} + \\theta_2 x_{N,2}\\\\\n",
    "\\end{cases}\n",
    "\n",
    " \\begin{cases}\n",
    "\\tilde{y}_1 = x_{0,1}\\theta_0 + \\theta_1 x_{1,1} + \\theta_2 x_{1,2}\\\\\n",
    "\\tilde{y}_2 = x_{1,1}\\theta_0 + \\theta_1 x_{2,1} + \\theta_2 x_{2,2}\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "\\tilde{y}_i = x_{i,1}\\theta_0 + \\theta_1 x_{i,1} + \\theta_2 x_{i,2}\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "\\tilde{y}_N = x_{N,1}\\theta_0 + \\theta_1 x_{N,1} + \\theta_2 x_{N,2}\\\\\n",
    "\\end{cases}\n",
    "\n",
    "Или тоже самое можно записать в матричном виде:  \n",
    "\\begin{equation*}\n",
    " \\begin{pmatrix}\n",
    "x_{1,0}& x_{1,1}& x_{1,2} \\\\\n",
    "x_{2,0}& x_{2,1}& x_{2,2} \\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "x_{i,0}& x_{i,1}& x_{i,2} \\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "x_{N,0}& x_{N,1}& x_{N,2} \\\\\n",
    "\\end{pmatrix}\\cdot\n",
    "\\begin{pmatrix}\n",
    "    \\theta_0\\\\\n",
    "    \\theta_1\\\\\n",
    "    \\theta_2\n",
    "  \\end{pmatrix}=\\begin{pmatrix}\n",
    "x_{0,1}\\theta_0 + \\theta_1 x_{1,1} + \\theta_2 x_{1,2}\\\\\n",
    "x_{1,1}\\theta_0 + \\theta_1 x_{2,1} + \\theta_2 x_{2,2}\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "x_{i,1}\\theta_0 + \\theta_1 x_{i,1} + \\theta_2 x_{i,2}\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "\\cdot\\\\\n",
    "x_{N,1}\\theta_0 + \\theta_1 x_{N,1} + \\theta_2 x_{N,2}\\\\\n",
    "  \\end{pmatrix}=\n",
    "  \\begin{pmatrix}\n",
    "    \\tilde{y}_1\\\\\n",
    "    \\tilde{y}_2\\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "    \\tilde{y}_i\\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "    \\cdot\\\\\n",
    "    \\tilde{y}_N\\\\\n",
    "  \\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\tilde{y} = X\\Theta.\n",
    "\\end{equation*}\n",
    "\n",
    "$x_{i, 0} = 1$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала составим матрицу $X$ из наших признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(X1, X2):\n",
    "    X_ones = np.ones_like(X1)\n",
    "    return np.column_stack([X_ones, X1, X2])\n",
    "\n",
    "X = create_data(X_room, X_lstat)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим начальные параметры весов случайными числами от 0 до 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta = np.random.random_sample(size=(3,))\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем линейную функцию от наших параметров и данных (функция делает $N$ предсказаний по параметрам $\\Theta$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_function(X, Theta):\n",
    "    return np.dot(X, Theta) #X @ Theta\n",
    "\n",
    "y_pred = linear_function(X, Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы можем сделать предсказание для всех квартир из выборки, определим функцию ошибки от параметров $\\Theta$ :\n",
    "\n",
    "\\begin{equation*}\n",
    "Loss(\\Theta) = \\dfrac{1}{N}\\sum_{i=1}^{N}{(\\tilde{y_i} - y_i)^2}= \\dfrac{1}{N} \\sum_{i=1}^{N}{(X_i\\Theta - y_i)^2}\n",
    "\\end{equation*}\n",
    "\n",
    "Где $N$ - это количество квартир, $y_i$ - реальная цена квартиры, $\\tilde{y_i}$ - предсказанная цена для $i$-oй квартиры.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем функцию ошибку наших предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE_Loss(X, Theta, y_true):\n",
    "    y_pred = linear_function(X, Theta)\n",
    "    return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "print(MSE_Loss(X, Theta, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы хотим минимизировать данную ошибку, для этого нам надо правильно подобрать параметры $\\Theta$.  \n",
    "\n",
    "Для нахождения параметров $\\Theta$, также используем градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как у нас 3 параметра $\\theta_0, \\theta_1, \\theta_2$, которые мы хотим найти, надо брать частную производную по каждому из них.  \n",
    "Посчитаем частную производную по каждому параметру от нашей функции ошибки:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\dfrac{\\partial Loss(\\Theta)}{\\partial \\theta_j} = \\dfrac{\\partial}{\\partial \\theta_j}(\\dfrac{1}{N} \\sum_{i=1}^{N}{(X_i\\Theta - y_i)^2})\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\dfrac{\\partial Loss(\\Theta)}{\\partial \\theta_j} = \\dfrac{2}{N} \\sum_{i=1}^{N}(X_i\\Theta - y_i)\\dfrac{\\partial (X_i\\Theta  - y_i)}{\\partial \\theta_j}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\dfrac{\\partial Loss(\\Theta)}{\\partial \\theta_j} = \\dfrac{2}{N} \\sum_{i=1}^{N}(X_i\\Theta - y_i)\\dfrac{\\partial (\\theta_0x_{i, 0} + \\theta_1 x_{i,1} + \\theta_2 x_{i,2}  - y_i)}{\\partial \\theta_j}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\dfrac{\\partial Loss(\\Theta)}{\\partial \\theta_j} = \\dfrac{2}{N} \\sum_{i=1}^{N}(X_i\\Theta - y_i) x_{ij}\n",
    "\\end{equation*}\n",
    "  \n",
    "$j = 0,1,2$.  \n",
    "$y_i$ - это реальная цена на квартиру, она константа, производная от константы равна нулю.  \n",
    "\n",
    "\n",
    "$\\tilde{y_i} = X_i\\Theta = \\theta_0x_{i,0} + \\theta_1x_{i,1} +  \\theta_2x_{i,2}$ - наше предсказание.   \n",
    "\n",
    "\n",
    "Частная производная\n",
    "$\\dfrac{\\partial \\tilde{y_i}}{\\partial \\theta_j} = x_{i,j}$.  \n",
    "$x_{i,0} = 1$.  \n",
    "\n",
    "Взяв частную производную по каждому параметру  $\\theta_j$, получим вектор градиент функции ошибки:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla Loss(\\Theta) =\n",
    "   \\begin{bmatrix}\n",
    "   \\dfrac{2}{N} \\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,0}\\\\\n",
    "   \\dfrac{2}{N} \\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,1}\\\\\n",
    "   \\dfrac{2}{N} \\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,2}\\\\\n",
    "   \\end{bmatrix}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приравняв каждую частную производную (элемент вектора градиента) к нулю и решив систему уравнений, сможем найти наилучшие параметры $\\Theta$.\n",
    "   \n",
    " \\begin{cases}\n",
    "   \\dfrac{2}{N} \\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,0} = 0\\\\\n",
    "   \\dfrac{2}{N} \\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,1} = 0\\\\\n",
    "   \\dfrac{2}{N} \\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,2} = 0\\\\\n",
    " \\end{cases}\n",
    "\n",
    "   Но делать это не целесообразно. Для решения данной системы в компьютере потребуется построить матричное уравнение. А в процессе решения потребуется найти обратную матрицу (сложность $O(n^3)$). Данная операция является очень медленной, даже на современных компьютерах. В данном примере у нас всего 2 входных параметра (RM и LSTAT) и $N=506$ значений $X$. Вычисления обратной матрицы для нашего примера займет микросекунды. Но в реальных приложениях обычно бывает и по десяткам тысяч входных параметров и сотни миллионов значений. Нахождения обратной матриц для таких задач займет несравнимо много времени по сравнению с градиентным спуском. Поэтому в промышленности применяется именно градиентный спуск. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем подсчет градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_function(Theta, X, y_true):\n",
    "    grad = np.zeros_like(Theta)\n",
    "    y_pred = linear_function(X, Theta)\n",
    "    for j in range(Theta.shape[0]):       \n",
    "        grad[j] = 2*np.mean((y_pred - y_true)* X[:,j])\n",
    "    return grad\n",
    "\n",
    "gard = gradient_function(Theta, X, y)\n",
    "print(gard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для нашего примера с 3 коэффициентами, алгоритм градиентного спуска будет выглядеть следующим образом:  \n",
    "$\\theta_{j_{new}} = \\theta_j - \\alpha \\dfrac{\\partial Loss(\\Theta)}{\\partial \\theta_j}$  \n",
    "$\\theta_{j_{new}} = \\theta_j - \\alpha  \\dfrac{2}{N} \\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,j}$\n",
    "\n",
    "Тогда обновление вектора $\\Theta$ будет выглядеть следующим образом:\n",
    " \n",
    "\\begin{equation*}\n",
    "   \\theta_{0_{new}} = \\theta_0 - \\alpha  \\dfrac{2}{N}\\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,0}\\\\\n",
    "   \\theta_{1_{new}} = \\theta_1 - \\alpha  \\dfrac{2}{N}\\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,1}\\\\\n",
    "   \\theta_{2_{new}} = \\theta_2 - \\alpha  \\dfrac{2}{N}\\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,2}\n",
    "\\end{equation*}\n",
    "\n",
    "Выполняем данную процедуру в цикле заданное число раз, либо пока наши параметры не перестанут изменяться на величину меньшую, чем некоторая нами заданная величина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм градиентного спуска c 3 коэффициентами можно описать следующим образом.\n",
    "\n",
    "* Выбираем случайное значение для $\\theta_0, \\theta_1, \\theta_2 $\n",
    "* Повторить $iter$ раз:\n",
    "\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\theta_{j_{new}} = \\theta_j - \\alpha \\dfrac{\\partial Loss(\\Theta)}{\\partial \\theta_j},\n",
    "    j = 0, 1, 2$\n",
    "\n",
    "Где $\\alpha$ это коэффициент, который мы выбираем.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец реализуем градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(Theta, X, y, alpha, iters):        \n",
    "    theta = Theta\n",
    "    for i in range (iters):\n",
    "        theta = theta - alpha * gradient_function(theta, X, y)\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_opt = gradient_descent(Theta, X, y, 0.0001, 10000)\n",
    "MSE_Loss(X, theta_opt, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь визуализируем полученный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_new_3d_data_and_hyp_grad_des(X_room, X_lstat, y, theta_opt[0], theta_opt[1], theta_opt[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание на всех данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы использовали всего два признака RM и LSTAT для предсказания цен на недвижимость.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем использовать все."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all, y = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${X}_i = \\begin{pmatrix}1 & x_{i, 1} &  x_{i, 2} & x_{i, 3} & \\ldots, x_{i, 13}\\end{pmatrix}.$\n",
    "\n",
    "\n",
    "$\\Theta = \\begin{pmatrix}\\theta_0& \\theta_1& \\theta_2& \\theta_3& \\ldots, \\theta_{13}\\end{pmatrix}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\tilde{y}_i= \\begin{pmatrix}x_{i, 0} & x_{i, 1}& x_{i, 2}& \\ldots& x_{i, 13}\\end{pmatrix} \\begin{pmatrix}\n",
    "    \\theta_0\\\\\n",
    "    \\theta_1\\\\\n",
    "    \\theta_2\\\\\n",
    "    \\cdots\\\\\n",
    "    \\theta_{13}\\\\\n",
    "  \\end{pmatrix} =  \\sum_{j=0}^{13} \\theta_j x_{i, j} = X_i\\Theta.\n",
    "\\end{equation*}\n",
    "\n",
    " $x_{i, 0} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ones(X):\n",
    "    return np.hstack([np.ones(len(X)).reshape(-1,1), X])\n",
    "\n",
    "X_all_wo = add_ones(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_all_wo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию ошибки от параметров $\\Theta$ :\n",
    "\n",
    "\\begin{equation*}\n",
    "Loss(\\Theta) = \\dfrac{1}{N}\\sum_{i=1}^{N}{(\\tilde{y_i} - y_i)^2}= \\dfrac{1}{N} \\sum_{i=1}^{N}{(X_i\\Theta - y_i)^2}\n",
    "\\end{equation*}\n",
    "\n",
    "Где $N$ - это количество квартир, $y_i$ - реальная цена квартиры, $\\tilde{y_i}$ - предсказанная цена для $i$-oй квартиры.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "   \\theta_{0_{new}} = \\theta_0 - \\alpha  \\dfrac{2}{N}\\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,0}\\\\\n",
    "   \\theta_{1_{new}} = \\theta_1 - \\alpha  \\dfrac{2}{N}\\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,1}\\\\\n",
    "   \\cdot\\\\\n",
    "   \\cdot\\\\\n",
    "   \\cdot\\\\\n",
    "   \\theta_{j_{new}} = \\theta_j - \\alpha  \\dfrac{2}{N}\\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,j}\\\\\n",
    "   \\cdot\\\\\n",
    "   \\cdot\\\\\n",
    "   \\cdot\\\\\n",
    "   \\theta_{m_{new}} = \\theta_m - \\alpha  \\dfrac{2}{N}\\sum_{i=1}^{N} (X_i\\Theta - y_i)x_{i,m}\\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный алгоритм градиентного спуска c $m$ коэффициентами можно описать следующим образом.\n",
    "\n",
    "* Выбираем случайное значение для $\\theta_0, \\theta_1,...,\\theta_m $\n",
    "* Повторить $iter$ раз:\n",
    "\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\theta_{j_{new}} = \\theta_j - \\alpha \\dfrac{\\partial Loss(\\Theta)}{\\partial \\theta_j},\n",
    "    j = 0, 1, ..., m$\n",
    "\n",
    "Где $\\alpha$ это коэффициент, который мы выбираем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_function(Theta, X, y_true):\n",
    "    grad = np.zeros_like(Theta)\n",
    "    y_pred = linear_function(X, Theta)\n",
    "    for j in range(Theta.shape[0]):       \n",
    "        grad[j] = 2*np.mean((y_pred - y_true)* X[:,j])\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta_all = np.random.random_sample((X_all.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_Loss(X_all, Theta_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_opt = gradient_descent(Theta_all, X_all, y, 0.000001, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(MSE_Loss(X_all, theta_opt, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В прошлом примере у нас не получилось обучить наш пример методом градиентного спуска. Давайте попробуем понять почему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть данные, которые были сгенерированы функцией ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y =  - 10 + x_1 + 2x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это функция вида:\n",
    "\n",
    "$y =  \\theta_0 + \\theta_1x_1 + \\theta_2x_2 $, \n",
    "\n",
    "где  $\\theta_0=-10$, $\\theta_1 = 1$, $\\theta_2=2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сгенерируем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.uniform(1, 10, 1000)\n",
    "X2 = np.random.uniform(0, 1, 1000)\n",
    "X = np.column_stack([X1, X2])\n",
    "X = add_ones(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У $X1$ диапозон от 1 до 10, а у $X2$ в десять раз меньше - от 0 до 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_theta = np.array([-10, 1, 2])\n",
    "y = linear_function(X, real_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_new_3d_data(X[:, 1], X[:, 2], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(MSE_Loss(X, real_theta, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У $X1$ диапазон от 1 до 10, а у $X2$ в десять раз меньше - от 0 до 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_init = np.array([-10, 0.5, 0.5])\n",
    "plot_grad(X, theta_init, y, a=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что бы решить эту проблему нужно привести данные к одному диапазону. То есть, нормализовать данные.\n",
    "\n",
    "Это можно решить с помощью стандартизации.\n",
    "\n",
    "Для каждой колонки (часто ее называют фича) нужно посчитать ее среднее и стандартное отклонение (среднеквадратическое отклонение). Затем нужно из каждого элемента колонки вычесть среднее и поделить это на стандартное отклонение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Среднее значение (мат. ожидание): $E(X) = \\dfrac{1}{N}\\sum_i^NX_i$\n",
    "\n",
    "* Дисперсия: $D(X) = \\dfrac{1}{N}\\sum_i^N (X_i - E(X))^2$\n",
    "\n",
    "* Стандартное отклонение: $\\sigma_X = \\sqrt{D(X)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X = \\dfrac{X - E(X)}{\\sqrt{D(X)}} = \\dfrac{X - E(X)}{\\sigma_X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = X.mean(axis=0)\n",
    "stds = X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(means, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_n = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, X_n.shape[1]):\n",
    "    X_n[:, i] = (X_n[:, i] - means[i]) / stds[i]\n",
    "print(X_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_grad(X_n, theta_init, y, a=0.25, k_min=-3, k_max=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "print(scaler.mean_, means)\n",
    "print(scaler.scale_, stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all, y = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_all_normalize = scaler.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all_normalize_with_one = add_ones(X_all_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta = np.random.random_sample((X_all_normalize_with_one.shape[1]))\n",
    "theta_opt = gradient_descent(Theta, X_all_normalize_with_one, y, 0.1, 300)\n",
    "print(theta_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSE_Loss(X_all_normalize_with_one, theta_opt, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда пайплайн для обучения модели выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Получить данные.\n",
    "2. Стандартизировать их.\n",
    "3. Добавить единицу.\n",
    "4. Обучить модель.\n",
    "5. Оценить результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Полиномиальная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постановка задачи - предсказание расхода топлива в зависимости от скорости.\n",
    "\n",
    "Данные для первой ступени ракеты, но задача может быть актуальна и для автомобилистов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_data_for_polynom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_poly_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_theta = np.array([0.0, 0.0])\n",
    "\n",
    "alpha = 0.001\n",
    "iters = 10000\n",
    "X_wo = np.column_stack([np.ones_like(X_train), X_train])\n",
    "lin_theta_opt = gradient_descent(lin_theta, X_wo, y_train, alpha, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize_prediction(X_train, y_train, linear_function(X_wo, lin_theta_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия хорошо работает в тех случаях, когда имеется линейная зависимость между данными.  Но что делать, если данные распределены нелинейно, если зависимость более сложная, как в нашем примере?\n",
    "В данном случае линейная регрессия слишком грубо описывает данные, что приводит к большим ошибкам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полиномы\n",
    "\n",
    "Полиномом степени n называется функция:\n",
    "\n",
    "$poly(X) = \\theta_n X^n + \\theta_{n-1} X^{n-1}  \\ldots + \\theta_1 X + \\theta_0$. \n",
    "\n",
    "Известное вам квадратное уравнение — это полином второй степени. \n",
    "\n",
    "$quadratic(X) = \\theta_2 X^2 + \\theta_1 X + \\theta_0$, или как вы привыкли его видеть: \n",
    "\n",
    "$quadratic(X) = a X^2 + b X + c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример параболы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parabola()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример полиномов больших степеней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_polynoms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае полином $n$-ой степени может иметь до $n$ корней, а значит пересекает ось $Х$ в $n$ точках (если $n$ корней). Для того, чтобы это было возможно он должен \"колебаться\" вверх-вниз. Т.е. чем выше степень полинома, тем больше таких \"волн\" в нем может быть.\n",
    "\n",
    "Соответственно, такие функции могут описать более сложные зависимости данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полиномы для линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим решение задачи на примере многочлена степени 5. Напомним, наша задача - нахождение расхода топлива 1-ой ступени в зависимости от скорости. Предположим, что решение будет иметь следующий вид:\n",
    "\n",
    "$y = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 + \\theta_5 x^5$\n",
    "\n",
    "Такая модель по-прежнему называется линейной, поскольку все коэффициенты (а т.е. веса модели) линейны. Квадраты и прочие степени появились только у $x$, т.е. у признаков модели. Получение таких признаков достигается просто возведением в нужную степень. Т.е. теперь мы будем передавать в модель не один признак $x$, a набор признаков $\\begin{pmatrix} x & x^2 & x^3 & x^4 & x^5\\end{pmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример:\n",
    "у нас имеется набор данных:\n",
    "одна строка - один пример данных\n",
    "\n",
    "| Признак | Целевые метки |\n",
    "|---------|---------------|\n",
    "| $x$       | $y$             |\n",
    "| 4.09    | 24            |\n",
    "| 4.96    | 21.6          |\n",
    "| ...     | ...           |\n",
    "\n",
    "\n",
    "Что будет теперь:\n",
    "\n",
    "| Признаки |   -   |  -  |  -  |  -   | Целевые метки |\n",
    "|----------|-------|-----|-----|------|---------------|\n",
    "| $x$      | $x^2$ | $x^3$ | $x^4$ | $x^5$  | $y$            |\n",
    "| 4.09     | 16.73 | 68.42  | 279.83 | 1144.5 | 24            |\n",
    "| 4.96     | 24.6 | 122.02 | 605.24 | 3001.98 | 21.6          |\n",
    "| ...      | ...   | ... | ... | ...  | ...           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это до сих пор линейая регрессия потому что:\n",
    "\n",
    "$y = \\theta_0 + \\theta_1 x + \\theta_2 x_2 + \\theta_3 x_3 + \\theta_4 x_4 + \\theta_5 x_5$,\n",
    "\n",
    "где \n",
    "\n",
    "$x_2 = x^2$\n",
    "\n",
    "$x_3 = x^3$\n",
    "\n",
    "$x_4 = x^4$\n",
    "\n",
    "$x_5 = x^5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть, у нас есть матрица $X$. \n",
    "\n",
    "Предсказания делаются функцией: \n",
    "\n",
    "$y = X\\Theta$.\n",
    "\n",
    "Матрица с данными умножается на матрицу коэффициентов.\n",
    "\n",
    "То есть, нам не важно, что из себя представляют значения матрицы $X$. Это могут быть как просто данные тогда это обычная линейная регрессия. А если это полиномиальные значения, то получается полиномиальная регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\mathbf{X} = \\begin{pmatrix}\n",
    "1 & x_0 & x_0^2 &\\dots & x_0^m\\\\\n",
    "1 & x_1 & x_1^2 &\\dots & x_1^m \\\\\n",
    "\\cdots \\\\\n",
    "1& x_N & x_N^2 &\\dots & x_N^m\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "1 & x_{0, 1} & x_{0, 2} &\\dots & x_{0, m}\\\\\n",
    "1 & x_{1, 1} & x_{1, 2} &\\dots & x_{1, m} \\\\\n",
    "\\cdots \\\\\n",
    "1& x_{N, 1} & x_{N, 2} &\\dots & x_{N, m}\n",
    "\\end{pmatrix}  \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализуем регрессию на sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "poly_transformer = PolynomialFeatures(5)\n",
    "X_poly = poly_transformer.fit_transform(X_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_poly_scaled = scaler.fit_transform(X_poly)\n",
    "X_poly_scaled[:, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_poly_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor = LinearRegression().fit(X_poly_scaled, y_train)\n",
    "y_pred = regressor.predict(X_poly_scaled)\n",
    "print(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_poly_results(X_poly_scaled, y_train, poly_transformer, scaler, regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм для полиномиальной регрессии:\n",
    "\n",
    "1. Сгенерировать полиномиальные фичи\n",
    "2. Стандартизировать параметры (кроме единичной колонки)\n",
    "3. Обучить линейную регрессию\n",
    "4. Оценить результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Переобучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_polynom(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим мы получили новые данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = get_more_data_for_polynom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_poly_data(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_polynom(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для борьбы с переобучением набор данных делиться на два сета:\n",
    "    1. Набор для тренировки.\n",
    "    2. Набор для тестирования.\n",
    "    \n",
    "Обычно 80% идет на набор для тренировки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_polynom(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Недообучение: большая ошибка на тренировочных и тестированных данных.\n",
    "* Переобучении: маленькая ошибка на тренировочных данных и большая ошибка тестированных данных.\n",
    "* Хорошо обученная модель: маленькая ошибка на тренировочных данных и маленькая ошибка тестированных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE\n",
    "\n",
    "MSE не единственная функция ошибки, которая применяется для обучения регрессии.\n",
    "\n",
    "$MAE = \\frac{1}{N}\\sum_{i=0}^{N}{|\\hat{y_i} - y_i|}= \\frac{1}{N} \\sum_{i=0}^{N}{|X_i\\Theta - y_i|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это то, насколько в среднем ошибается наша модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_poly = poly_transformer.transform(X_test.reshape(-1,1))\n",
    "X_test_poly = scaler.transform(X_test_poly)\n",
    "X_test_poly[:, 0] = 1\n",
    "y_test_pred = regressor.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(mean_absolute_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МАЕ как функция ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае производная от $|x|$ не определена в точке 0, во всех остальных случаях ее можно определть, как $|x|'= \\dfrac{|x|}{x}$.\n",
    "\n",
    "\n",
    "При $x > 0, \\ |x| = x, \\ \\dfrac{|x|}{x} = \\dfrac{x}{x} = 1$.\n",
    "\n",
    "При $x < 0, \\ |x| = -x, \\ \\dfrac{|x|}{x} = \\dfrac{-x}{x} = -1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае мы можем доопределить производную от $|x|$ в нуле значением 0. Тогда она совпадет с функцией знака:\n",
    "\\begin{equation*}\n",
    " sign(x) = \n",
    " \\begin{cases}\n",
    "   1 &\\text{x > 0}\\\\\n",
    "   0 &\\text{x = 0}\\\\\n",
    "   -1 &\\text{x < 0}\n",
    " \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Теперь мы можем посчитать градиент функции потерь:  \n",
    "\\begin{equation*}\n",
    "\\frac{\\partial Loss(\\Theta)}{\\partial \\theta_j} = \\frac{1}{N} \\sum_{i=1}^{N} sign(X_i\\Theta - y_i) x_{ij}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla Loss(\\Theta) = \n",
    " \\begin{bmatrix}\n",
    "   \\frac{1}{N} \\sum_{i=1}^{N} sign(X_i\\Theta - y_i)x_{i0}\\\\\n",
    "   \\frac{1}{N} \\sum_{i=1}^{N} sign(X_i\\Theta - y_i)x_{i1}\\\\\n",
    "   \\cdots\\\\\n",
    "   \\frac{1}{N} \\sum_{i=1}^{N} sign(X_i\\Theta - y_i)x_{im}\\\\\n",
    " \\end{bmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В чем разница между MAE и MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реакция на выбосы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " plot_outlier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница в MSE возводиться в квадрат. Поэтому ошибка на выбросе будет больше учитываться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_regression_with_outlier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скорость алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_mae_mse()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На большом $\\alpha$ MAE не сходиться к локальному минимуму. Но при маленьком $\\alpha$ MAE долго сходиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чему мы сегодня научились\n",
    "\n",
    "* Линейная регрессия на большом количестве фич\n",
    "* Стандартизация и нормализация данных\n",
    "* Полиномиальная регрессия\n",
    "* Переобучение, недообучение\n",
    "* MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа\n",
    "\n",
    "Обучить полиномиальную регрессию градиентом спуском на средней абсолютной ошибке."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {
    "03fc38044a514408b9de41fa70bf122f": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "19b7b5447a594ae1a20b764ac13118cc": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "28304c0dfbab44f5a851af84bf5947d3": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "3f700e837fd046ddb14ee8776ac8bc04": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "50d7c06a111e43c1860a5b10a576bfd3": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "a74e340d7bb24d9bb020ad7dd982e764": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "d5593dc80c0445c7ae64c7da2d37f72f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "d644b9b546b849c6b17acb3be1f1952b": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "eac5158d5b6c45c4afa73b58b8b0e58a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f4cec2743faf43ad9b8e7c828c6ee76a": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
