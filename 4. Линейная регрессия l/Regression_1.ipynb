{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Линейная регрессия\n",
    "\n",
    "Всем привет. В данном уроке мы разберём такую тему как линейная регрессия. \n",
    "\n",
    "Мы рассмотрим какие виды проблем решает линейная регрессия и поговорим про то, как можно использовать математику для решения этих проблем. \n",
    "\n",
    "В этом уроке мы разберем линейные функции, функцию потерь, производную и поговорим про один из самый популярный и самых полезный алгоритм машинного обучения - градиентный спуск.\n",
    "\n",
    "Но просто рассматривать теорию без реализации не слишком полезно. Поэтому мы также реализуем все эти функции и алгоритмы на Python и NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "И первый вопрос который мы сейчас рассмотрим это - ***почему мы изучаем линейную регрессию, а не глубокие нейронные сети?*** \n",
    "\n",
    "Многие из вас наверняка уже слышали про линейную регрессию в университете или в даже в школе. И сейчас вы задаетесь вопросом: а почему мы будем изучать ее, а не что-то что сейчас на слуху, например, нейронные сети. \n",
    "\n",
    "Во-первых, линейная регрессия довольно простая для понимания, но при этом, идеи, которые мы сегодня рассмотрим на примере линейной регрессии повсеместно применяются в машинном обучении. Например, алгоритм обучения линейной регрессии также используется и в нейронных сетях (с небольшими доработками).\n",
    "\n",
    "Во-вторых, пускай линейная регрессия и является довольно старой идеей, она до сих применяется для решения многих задач. Она встроена во многие базы данных, такие как ClickHouse и даже доступна в Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Постановка задачи \n",
    "\n",
    "Давайте представим, что к нам пришли социологи из какого-то университета, например, ВШЭ или ФизТеха.\n",
    "Они опросили студентов и узнали какую часть свободного времени они тратят на учебу. Назовем это $X$.  А также они знают среднюю оценку студента по всем предметам. Обозначим это как $y$. Это социологи из новомодного университета, где десятибалльная система. \n",
    "\n",
    "И они хотят научиться по доли потраченного на учебу времени определять среднюю оценку студента. У них есть несколько примеров данных где есть пары $х$ и $у$. \n",
    "\n",
    "То есть, наша задача найти зависимость между $Х$ и $y$. \n",
    "\n",
    "То есть, нужно найти функцию $f(X) = y$, где $X$ это доля потраченного на учебу времени, а $y$ это средняя оценка. В общем случае это и есть задача регрессии.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Можно представить, что эти пары ($x$, $y$) - это значения функции $f(X)$ в точках $Х$. И задача регрессии — это построить функцию (некую линию) которая может *описать* эти данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Например,\n",
    "\n",
    "*нам говорят, Х=0.1. Мы берем это число, помещаем ее нашу функцию и получаем значение для у.* \n",
    "\n",
    "$f(0.1) = 3$\n",
    "\n",
    "*И мы говорим в ответ: у=3*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Другой пример регрессии*. У нас есть интернет сайт, и мы хотим предсказать сколько посетителей у нас будет в определенное время, при этом у нас есть статистика посещений сайта от времени. Наша задача - используя имеющиеся данные о загруженности в прошлом, предсказать количество посетителей в интересующие нас время. \n",
    "\n",
    "То есть по имеющимся данным построить зависимость интересующей нас переменной от каких то других параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В общем случае задача регрессии - это по входным данным найти число в каком-то *непрерывном* диапазоне. Например: $(-1, 1)$ или же $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Рассмотрим подробнее пример с $Х$ и $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Давайте загрузим данные. Для этого воспользуемся функциями, которые я подготовил специально для этого урока."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первой строчке мы подгрузим все вспомогательные функции, которые мы сегодня будем применять. \n",
    "\n",
    "Вторая строчка подгружает библиотеку NumPy, c помощью которой мы будем сегодня реализовывать все алгоритмы. \n",
    "\n",
    "В третьей строки мы загружаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from regression_helper import * # Подгружаем функции для визуализации\n",
    "import numpy as np              # Подгруджаем библиотеку NumPy\n",
    "\n",
    "X, y = get_data()               # Загружаем данные в X и y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого в векторе $X$ содержится доля свободного времени студента, потраченная на учебу, а в векторе $y$ средняя оценка. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь давайте посмотрим на эти данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "visualize_Xy(X, y)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$X$ и $y$ - это массивы NumPy ndarray с 20 элементами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем тип $X$ и тип $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Тип переменной X: {type(X)}\")\n",
    "print(f\"Тип переменной y: {type(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну давайте тогда и на значения посмотрим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения массива X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения массива y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "И давайте договоримся, когда я буду писать $X_i$ в тексте - это будет эквивалентно обращению к $i$-тому элемента массива $X$. Или тоже самое что ***X[i]*** в коде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить, значение $X[0]$ равно значению нулевого элемента X, выведенного выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Отобразим эти данные на графике. Черные точки - это пары $х$, $у$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Строим график с точками\n",
    "plot_data(X, y)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная функция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Мы видим, что чем больше $y$, тем выше $y$. Можно сделать вывод, что между этими данными есть зависимость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "А еще можно заметить, что точки примерно лежат на одной линии.\n",
    "\n",
    "То есть, эти точки можно описать какой-то линией, к которой прибавляется случайная ошибка (шум). За счет этого точки лежат не ровно на прямой, а как бы \"вокруг\" нее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Это позволяет нам предположить, что данная зависимость может описаться линейной функцией вида:\n",
    "\n",
    "$y = kX$, \n",
    "\n",
    "где $X$ это доля времени студента, $y$ средняя оценка, а $k$ - это некий коэффициент. Также $k$ называют параметром функции и весом функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как выглядят функции вида $y = kX$ с разными коэффициентами $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Двигая слайдер можно менять значение коэффициента. Черные точки это наши данные. Ну а черная линяя - это функция $y=kX$ с различными значения $k$.\n",
    "\n",
    "Как видно по графику, наша функция $y=kX$ это линия. Ну а сам такой вид функции называется линейной функцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "choose_slope(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "График - это конечно хорошо. Нам нужно как-то применять эту функцию для предсказания значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Давайте реализуем линейную функцию на Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшая ремарка. \n",
    "\n",
    "Перед каждой ячейкой с кодом будет текст с задачей, которая решает этот код и описание выходных и выходных данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Самая простая реализация линейной функции в самом простом виде выглядит так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого элемента $X_i$ массива $X$ реализовать функцию $f(X_i) = kX_i$.\n",
    "\n",
    "На входе:\n",
    "* Массив ndarray $X$;\n",
    "\n",
    "* Значение коэффициента $k$;\n",
    "\n",
    "На выходе:\n",
    "\n",
    "* На выходе массив ndarray со значениями $f(X_i) = kX_i$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy_f(X, k):\n",
    "    # Создаем результирующий список, где будем сохранять значения функции\n",
    "    result = []                  \n",
    "    \n",
    "    # Переменная i в цикле будет менять свое значение в диапазоне (range) от 0 до размера массива X (len(X))\n",
    "    for i in range(len(X)):    \n",
    "        \n",
    "        # Считаем значение y для i-этого элемента массива X\n",
    "        y_i = k*X[i]    \n",
    "        \n",
    "        # Добавляем результат в результирующий список\n",
    "        result.append(y_i)\n",
    "        \n",
    "    # Создаем из списка массив ndarray    \n",
    "    return np.array(result)\n",
    "\n",
    "print(dummy_f(X, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но это не самая лучшая реализация. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно воспользоваться возможностями NumPy. Из предыдущего урока по NumPy мы знаем, что в нем есть операция умножения массива на скаляр. Давайте ей воспользуемся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого элемента $X_i$ массива $X$ реализовать функцию $f(X_i) = kX_i$.\n",
    "\n",
    "На входе:\n",
    "* Массив ndarray $X$;\n",
    "\n",
    "* Значение коэффициента $k$;\n",
    "\n",
    "На выходе:\n",
    "\n",
    "* На выходе массив ndarray со значениями $f(X_i) = kX_i$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(X, k):\n",
    "    # Используем возможность ndarray и умножим массив X на скаляр k\n",
    "    # Результат этой операции это ndarray\n",
    "    return k*X\n",
    "\n",
    "print(f(X, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция выглядит очень компактно и можно заметить, что результаты совершенно одинаковы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом, эта функция также работает и для одного элемента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f(X[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция не только выглядит проще и компактнее, но также она и во много раз быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разница во времени выполнения функций dummy_f и f на массиве ndarray с 100000 элементов.\n",
    "\n",
    "Функция                | Среднее время (микросекунд) \n",
    "-----------------------|-----------------------------\n",
    "dummy_f     | 31400                       \n",
    "f                      | 70                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из таблицы, функция, написанная с помощью NumPy быстрее в 45 раз!\n",
    "\n",
    "*Примечание: время выполнения может отличаться на разных компьютерах.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ок. Мы научились реализовывать линейную функцию для различных $k$. Но это нам не отвечает на вопрос о том, какое $k$ подходит нам лучше всего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте снова посмотрим на различные линейные функции с различными $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "choose_slope(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть различные линейные функции с различными $k$. Но как определить какая из них лучшая? И желательно сделать это так, чтобы это можно было запрограммировать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для это введем **функцию ошибку**, также известную как **функцию потерь** или **loss function**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки - численное значение того, насколько хорошо наша функция описывает данные. В данном случает это то, насколько предсказанные значения нашей функции отличаются от реальных.\n",
    "\n",
    "Обозначается функция потерь как $Loss$, $L$ или $J$. Мы будем использовать $Loss$.\n",
    "\n",
    "Лучше всего не использовать значение $L$. $L$ - часто используется как обозначение для функции правдоподобия, которая также часто используется в машинном обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте визуализируем разницу между точками которые предсказывает функция $f(X) = kX$ и реальными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять же, черные точки - это реальные значения. Крестики - это предсказанаые значения в точках $X$. А красная линия это разница между придсказаными значениями и реальными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data_and_error(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту разницу можно использовать для оценки нашей функции $f(X) = kX$, конкретно оценки параметра $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть функция:  \n",
    "\n",
    "$\\widetilde{y} = f(X) = kX$\n",
    "\n",
    "Тогда $\\widetilde{y}$ - это предсказанные нами значения для $X$. \n",
    "\n",
    "А настоящие значения будут равны $y$. \n",
    "\n",
    "Тогда ошибку нашего предсказания на $i$-ом примере $\\widetilde{y}_i$ можно посчитать как: \n",
    "\n",
    "$error = \\widetilde{y}_i - y_i$\n",
    "\n",
    "Если нам не важно в большую или в меньшую сторону мы ошибаемся, можем избавиться от знака, взяв либо модуль, либо квадрат ошибки. Для начала давайте возьмем квадрат. О модуле мы поговорим в следующих уроках. Тогда ошибка $loss_i(k)$ на $i$-ом примере будет равна:\n",
    "\n",
    "$loss_i(k) = (\\widetilde{y}_i - y_i)^2$\n",
    "\n",
    "$loss_i(k) = (kX_i - y_i)^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на значения ошибок для наших точек для коэффициента $k = 25$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 25\n",
    "error_on_sample(X, y, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить, в начале разница отрицательная, а в после 6-го примера она становиться положительной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на квадрат разности между предсказанными значение и реальным для коэффициента $k = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 25\n",
    "quad_error_on_sample(X, y, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вся разница положительная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как это можно реализовать в Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 25\n",
    "# f(X, k) возвращает массив ndarray\n",
    "# y также массив ndarray\n",
    "# И как мы помним из предыдущего урока, в NumPy реализована возможность поэлементной разности между массивами\n",
    "errors = f(X, k) - y\n",
    "\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, за счет того, что в NumPy есть возможность поэлементного возведение в степень, посчитать квадратичную разность не составит труда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 25\n",
    "quad_errors = (f(X, k) - y)**2\n",
    "print(quad_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы научились оценивать ошибку предсказание на каждом примере. И у нас есть массив значений. Но хотелось бы иметь ровно одно число, которое даст оценку нашей функции. Сделать это довольно просто."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем посчитать среднюю ошибку $Loss(k)$ на всех примерах:\n",
    "\n",
    "$\\widetilde{y}_i = f(X_i) = kX_i$\n",
    "\n",
    "$Loss(k) = \\dfrac{1}{N} \\sum_{i=0}^{N}{(\\widetilde{y}_i - y_i)^2}$ \n",
    "\n",
    "$Loss(k) = \\dfrac{1}{N} \\sum_{i=0}^{N}{(f(X_i) - y_i)^2}$\n",
    "\n",
    "$Loss(k) = \\dfrac{1}{N} \\sum_{i=0}^{N}{(kX_i - y_i)^2} $\n",
    "\n",
    "Где $N$ - это количество примеров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая функция ошибки называется **среднеквадратичная ошибка (СКО)** или **mean squared error (MSE)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Немного про нотацию***.\n",
    "\n",
    "Функция потерь формально зависит от входных данных, реальных выходных данных, вида функции и параметров этой функции. \n",
    "\n",
    "То есть, $Loss(X, y, f, k)$. Но обычно, для краткости, мы предполагаем, что мы используем текущие $X$, $y$ и $f$ и пишем, что функция потерь зависит только от параметров функции -  $Loss(k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, сама функция потерь - это функция от одной переменной (параметра) $k$. То есть, это зависимость между выбранным параметром и ошибкой, которая у нас будет после предсказания с этим параметром."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте реализуем функцию ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для массива $X$ и реального значения $y$ необходимо реализовать функцию ошибки. \n",
    "\n",
    "На входе:\n",
    "\n",
    "\n",
    "* Массив входных значений $X$;\n",
    "\n",
    "* Массив реальных  выходных значений $y$;\n",
    "\n",
    "* Коэффициент $k$ функции $f(X)=kX$;\n",
    "\n",
    "\n",
    "На выходе:\n",
    "\n",
    "* На выходе значение функции ошибки $Loss(k)$;\n",
    "\n",
    "Формула функции ошибки:\n",
    "\n",
    "$Loss(k) = \\dfrac{1}{N} \\sum_{i=0}^{N}{(kX_i - y_i)^2} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(X, y, k):\n",
    "    \n",
    "    N = X.shape[0]                    # получаем размер вектора столбца\n",
    "    # или N = len(X)\n",
    "   \n",
    "    # создаем массив ошибок для каждого примера\n",
    "    loss_for_sample = (k*X - y)**2\n",
    "    \n",
    "    # берем среднее значение\n",
    "    loss = np.sum(loss_for_sample) / N      \n",
    "    \n",
    "    # или если переписать проще \n",
    "    # loss = np.mean((k*X - y)**2)\n",
    "    return loss\n",
    "\n",
    "k = 25\n",
    "print(loss_function(X, y, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим ошибки для разных $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data_and_loss(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Давайте теперь визуализируем всю функцию ошибки для всех функция значений $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Небольшая ремарка: функция ошибки ниже была получена не аналитически. Она была посчитана для огромного количества параметров $k$ от 0 до 40*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_all_loss(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графику видно, что если взять коэффициент $k$ = 10, то мы получим ошибку равную около 15. И можно заметить, что минимальное значение функции достигается около 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Производная функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша задача - это минимизации функции ошибки. То есть, нужно найти такое $k$, для которого функция $Loss(k)$ имеет минимальное значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения этой задачи обратимся к математике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте вспомним что такое *производная функции*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная функции $f(x)$ записывается как $f'(x)$ или же как $\\dfrac{d f(x)}{dx}$. Мы будем применять оба варианта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сама производная это то, насколько значение функции меняется в зависимости от изменения входного значения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Математически это выглядит так:*\n",
    "\n",
    "$f'(x_0) = lim_{\\Delta x \\rightarrow 0}\\dfrac{\\Delta y}{\\Delta x} = lim_{\\Delta x \\rightarrow 0}\\dfrac{f(x_0+\\Delta x) - f(x_0)}{\\Delta x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Звучит очень здорово, но очень не понятно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на не самое математичное определение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть некая функция $y = f(x)$.\n",
    "\n",
    "Возьмем точку $x_0$. Мы можем получить значение функции в этой точки $y_0 = f(x_0)$. \n",
    "\n",
    "А теперь возьмем точку рядом с $x_0$. Это можно сделать прибавив (или отняв) от $x_0$ какое-нибудь маленькое значение. Назовем его $\\Delta x$. \n",
    "\n",
    "То есть, мы получаем $y_1 = f(x_0 + \\Delta x)$.\n",
    "\n",
    "Теперь посмотрим на разницу между значениями функции в точке $x_0$ и $x_0 + \\Delta x$\n",
    "\n",
    "Она записывается как $\\Delta y$.\n",
    "\n",
    "$\\Delta y = f(x_0 + \\Delta x) - f(x_0)$\n",
    "\n",
    "И если разделить $\\Delta y$ на $\\Delta x$ то это и будет производная в точке $x_0$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть, производная равна:\n",
    "\n",
    "$f'(x_0) = \\dfrac{d f(x_0)}{dx} $\n",
    "\n",
    "$f'(x_0) = \\dfrac{\\Delta y}{\\Delta x} = \\dfrac{f(x_0+\\Delta x) - f(x_0)}{\\Delta x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но очень важно, что бы $\\Delta x$ был очень маленьким числом. Обычно говорят, что $\\Delta x$ стремится к 0. И пишут это как $\\Delta x \\rightarrow 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Геометрическая интерпритация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на функцию $f(x) = x^2 + 1.5$. Это функция параболы. \n",
    "\n",
    "На ее примере попробуем получить интуитивное понимание производной. \n",
    "\n",
    "Давайте еще раз перепишем формулу для производной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Delta y = f(x_0+\\Delta x) - f(x_0)$\n",
    "\n",
    "$f'(x_0) = \\dfrac{\\Delta y}{\\Delta x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возврастающая функция в точке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Рассмотрим пример производной для нее в точке $x_0 = 1.4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = 1.4\n",
    "derivation(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Красная точка - это значение функции $f(x_0)$ в точке $x_0$. \n",
    "\n",
    "Синяя точка - это значение функции $f(x_0+\\Delta x)$ в точке $x_0+\\Delta x$. \n",
    "\n",
    "Двигая слайдер, можно уменьшать значение $\\Delta x$.\n",
    "\n",
    "Между синей и крестной точки проведена секущая. Угол между ней и осью $X$ обозначим как $\\alpha$. \n",
    "\n",
    "Рассмотрим треугольник с катетами ${\\Delta y}$ и ${\\Delta x}$. Угол между катетом ${\\Delta x}$ и гипотенузой тоже будет равен $\\alpha$.  \n",
    "\n",
    "Из геометрии мы знаем что $tg(\\alpha) = \\dfrac{\\Delta y}{\\Delta x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устремляя $\\Delta x$ мы получаем производную. При этом, наша секущая между синей и красной точки стала касательной к функции в точке $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И мы получили $f'(1.4) = 2.8$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Убывающая функция в точке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример производной для функции в точке $x_0 = -1.3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = -1.3\n",
    "derivation(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все тоже самое. Уменьшая $\\Delta x$ мы получаем производную. И наша секущая становиться касательной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но можно заметить, что теперь наша касательная направлена в другую сторону, на убывание. И само значение производной стало отрицательной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно считать, что производная в точке показывает \"скорость\" изменения функции. Она положительна если функция растет вокруг точки и отрицательна, когда функция убывает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще ее можно интерпретировать как тангенс угола наклона $\\alpha$ касательной к точке.\n",
    "\n",
    "Обычно пишут что $f'(x_0) = tg(\\alpha)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть, если производная **положительная** в точке $x_0$, и мы возьмем значение немного *больше* чем $x_0$, то мы увидим, что значение функции в новой точке *возросло*. А если взять значение *меньшее* $x_0$, то значение функции будет *меньше* чем в точке $x_0$.\n",
    "\n",
    "Наоборот с отрицательным значением производной. Если производная **отрицательна** в точке $x_0$, и мы возьмем значение чуть *больше* чем $x_0$, то мы увидим, что значение функции *уменьшилось*. А если взять значение *меньшее* $x_0$, то значение функции будет *больше* чем в точке $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доказательство положительной производной для возрастающей функции находится в конце ноутбука в приложении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Производная в экстремуме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим поведение производной в экстремумах. \n",
    "\n",
    "Экстремум - это точка при которой функция принимает максимальные и минимальные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = 0\n",
    "derivation(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть, в точках минимума и максимума производная равна 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аналитический вывод производной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте получим производную аналитически."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомню, наша функция выглядит как $f(x) = x^2 + 1.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В какой-то точке $x_0$ производная будет равна:\n",
    "\n",
    "$f'(x_0) = \\dfrac{f(x_0+\\Delta x) - f(x_0)}{\\Delta x}$\n",
    "\n",
    "$f(x_0+\\Delta x) = (x_0 + \\Delta x)^2 + 1.5 = x_0^2 + 2x_0\\Delta x + \\Delta x^2 + 1.5$\n",
    "\n",
    "$ \\dfrac{f(x_0+\\Delta x) - f(x_0)}{\\Delta x} = \\dfrac{x_0^2 + 2x_0\\Delta x + \\Delta x^2 + 1.5 - (x_0^2 + 1.5) }{\\Delta x} = \\dfrac{2x_0\\Delta x + \\Delta x^2}{\\Delta x}$\n",
    "\n",
    "$\\dfrac{2x_0\\Delta x + \\Delta x^2}{\\Delta x} = 2x_0 + \\Delta x$\n",
    "\n",
    "И если мы будем считать $\\Delta x$ очень маленьким числом, тогда \n",
    "\n",
    "$f'(x_0) = 2x_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И если подставить значения для наших функций, то все должно сойтись с тем, что мы нашли исходя из геометрических соображений.\n",
    " \n",
    " $f'(1.4) = 2 \\cdot 1.4 =  2.8$\n",
    " \n",
    " $f'(-1.3) = 2 \\cdot (-1.3) = -2.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы помните из школьного курса, обычно производные считаются аналитически с помощью таблиц и особых правил, о которых мы говорим далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И нет необходимости каждый раз использовать определение производной для ее подсчета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на производную для всех точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_simple_func_and_der()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Так зачем нам это все? Как это поможет нам решить проблему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я вам напомню, что наша задача найти минимум нашей функции потеть $Loss(k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем же производная может нам помочь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к нашей функции ошибки посмотрим на ее производные в разных точках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data_and_loss(X, y, with_der=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим мы видим что производная равна отрицательному значению. Это значит что функция ошибки в окрестности данной точки убывает. То есть, если взять $k$ поменьше, то ошибка будет расти, а если по больше, то ошибка будет убывает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь допустим производная положительна. Это значит что функция ошибки в окрестности данной точки возрастает. То есть, если взять $k$ побольше, то ошибка будет расти, а если поменьше, то ошибка будет убывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда найти минимальное значение функции ошибки довольно просто.\n",
    "\n",
    "Мы берем случайное значение $k$. Считаем значение производной для этого параметра. Если производная положительная, берем новое $k$ чуть меньше чем было, если производная отрицательная, то берем новое значение для $k$ чуть побольше. Это все повторяем до тех пор, пока нас не устроит значение ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но сначала давайте возьмем производную от нашей функции ошибки. Для этого рассмотрим следующие свойства производной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Свойства производных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Элементарные функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала посмотрим на таблицу с производными для элементарных функций (некоторых).\n",
    "\n",
    "| Элементарная функция $f(x)$ | Производная $\\dfrac{df(x)}{dx}$\n",
    "| -----  | --- |\n",
    "|  $a$   |  0  |\n",
    "|  $x$   |  1  |\n",
    "|  $ax$  |  a  |\n",
    "|  $x^2$  |  $2x$ |\n",
    "|  $x^n$  |  $nx^{n-1}$ |\n",
    "|  $\\ln(x)$  |  $\\dfrac{1}{x}$ |\n",
    "|  $ \\sin (x)$  | $\\cos (x)$  |\n",
    "|  $\\cos(x)$   |  $-\\sin (x)$ |\n",
    "|  $e^x$   |  $e^x$ |\n",
    "|  $a^x$   |  $a^x \\ln (a)$ |\n",
    "\n",
    "$a$ - это константа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Пример:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{dx^3}{dx} = (x^3)' = 3x^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Производная функции умноженную на константу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если функция умножается на константу, то производная берётся от функции без константы, затем это константа домножается на производную."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(af(x))' = af'(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Пример:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(10x)' = 10$\n",
    "\n",
    "$(20.1 x^3)' = 20.1 \\cdot 3 x^2 = 60.3 x^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Производная суммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная суммы (разности) равна сумме (разности) производных:\n",
    "\n",
    "Для двух функций:\n",
    "$(f_1(x) + f_2(x))' = f_1'(x) + f_2'(x)$\n",
    "\n",
    "В общем случае: $\\left(\\sum_n f_n(x) \\right)' = \\sum_n f_n'(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть, когда мы берем производную от суммы мы берем производную от каждого слагаемого и суммируем полученые производные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Пример:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x) = 3x^2 + 20ln(x) + 3$\n",
    "\n",
    "$f'(x) = (3x^2 + 20ln(x) + 3)'$\n",
    "\n",
    "$f'(x) = (3x^2)' + (20ln(x))' + (3)'$\n",
    "\n",
    "$f'(x) = 3\\cdot2x + 20\\cdot \\dfrac{1}{x} + 0$\n",
    "\n",
    "$f'(x) = 6x + \\dfrac{20}{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Производная сложной функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При взятии производной сложной функции использоваться цепное правило (chain rule)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интуитивное понимание. Мы смотрим какой порядок вычисления операций и вычисляем производную с последней операции по первую и перемножая их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но что это значит?\n",
    "\n",
    "Например, у нас есть функция $f(x) = sin(e^{3x})$.\n",
    "\n",
    "Что бы вычислить эту функцию нужно сначала рассчитать $u = 3x$. Затем $v = e^u$. И наконец $y = sin(v)$.\n",
    "\n",
    "То есть:\n",
    "\n",
    "1. $u = 3x$\n",
    "\n",
    "2. $v = e^u$\n",
    "\n",
    "3. $y = sin(v)$\n",
    "\n",
    "А что бы вычислить производную мы идем в обратном порядке. Сперва мы просто берем производную синуса (считая все то что в скобках за одну переменную), затем производную от экспоненты и наконец производную множителя.\n",
    "\n",
    "$\\dfrac{df(x)}{dx} = \\dfrac{d (sin(v))}{dv} \\dfrac{d (e^u)}{du} \\dfrac{d (3x)}{x} $\n",
    "\n",
    "$\\dfrac{df(x)}{dx} = cos(v) \\cdot e^u \\cdot 3x = cos(e^{3x}) \\cdot e^{3x} \\cdot 3x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математически это так:\n",
    "\n",
    "$v = \\psi(x)$\n",
    "\n",
    "$u = \\phi(v)$\n",
    "\n",
    "$y= f(u)$\n",
    "\n",
    "$\\dfrac{df(x)}{dx} = \\dfrac{df(u)}{du} \\cdot \\dfrac{du(v)}{dv} \\cdot \\dfrac{dv(x)}{dx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Еще пример:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = ln(10x)$\n",
    "\n",
    "$u = 10x$\n",
    "\n",
    "$y = ln(u)$\n",
    "\n",
    "$\\dfrac{dy}{dx} = \\dfrac{d (ln(u))}{du} \\cdot \\dfrac{d(10x)}{dx}$ \n",
    "\n",
    "$\\dfrac{d( ln(u))}{du} = \\dfrac{1}{u}$\n",
    "\n",
    "$\\dfrac{d(10x)}{dx} = 10$\n",
    "\n",
    "$\\dfrac{dy}{dx} = \\dfrac{1}{u} \\cdot 10 = \\dfrac{10}{10x} =  \\dfrac{1}{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*И еще один с суммой:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x) = (10x^2 + x)^3$\n",
    "\n",
    "$u = 10x^2 + x$\n",
    "\n",
    "$y = u^3$\n",
    "\n",
    "$\\dfrac{dy}{dx} = \\dfrac{d (y) }{du} \\cdot \\dfrac{du}{dx}$ \n",
    "\n",
    "$\\dfrac{dy}{dx} = \\dfrac{d (u^3) }{du} \\cdot \\dfrac{d(10x^2 + x)}{dx}$ \n",
    "\n",
    "$\\frac{d  (u^3)}{du} = 3u^2$\n",
    "\n",
    "$\\frac{d(10x^2 + x)}{dx} = 20x + 1$\n",
    "\n",
    "$\\frac{dy}{dx} = 3u^2 \\cdot(20x + 1) = 3(10x^2 + x)^2 \\cdot(20x + 1) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Производная функция ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напомню, как выглядит наша функция ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ J(k) = \\dfrac{1}{N}\\sum_{i=1}^{N}{(\\widetilde{y}_i - y_i)^2} $,\n",
    "\n",
    "$ J(k) = \\dfrac{1}{N}\\sum_{i=1}^{N}{(kX_i  - y_i)^2} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ее производная обозначается так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\dfrac{d(J(k))}{dk} = \\dfrac{d  \\left( \\dfrac{1}{N}\\sum_{i=1}^{N}{(kX_i  - y_i)^2} \\right) }{dk} $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно помнить, что в данном случае мы считаем, что $X$ и $y$ это константы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты обозначим производную это так:\n",
    "\n",
    "$ \\dfrac{d \\left( \\dfrac{1}{N}\\sum_{i=1}^{N}{(kX_i  - y_i)^2} \\right) }{dk} =  \\left( \\dfrac{1}{N}\\sum_{i=1}^{N}{(kX_i  - y_i)^2} \\right)_k'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала вспомним свойство производной функции, умноженной на константу:\n",
    "\n",
    "$\\left( \\dfrac{1}{N}\\sum_{i=1}^{N}{(kX_i  - y_i)^2} \\right)_k' = \\dfrac{1}{N} \\left( \\sum_{i=1}^{N}{(kX_i  - y_i)^2} \\right)_k'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь используем свойство производной от суммы:\n",
    "\n",
    "$ \\dfrac{1}{N} \\left( \\sum_{i=1}^{N}{(kX_i  - y_i)^2} \\right)_k' = \\dfrac{1}{N}  \\sum_{i=1}^{N}\\left((kX_i  - y_i)^2 \\right)_k'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось взять производную того, что под знаком суммы. \n",
    "\n",
    "Это производная сложной функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(k) = (kX_i  - y_i)^2$\n",
    "\n",
    "$u = kX_i  - y_i$\n",
    "\n",
    "$ \\dfrac{d(f(k))}{dk} = \\dfrac{d(u^2)}{du} \\dfrac{du}{dk} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{d(u^2)}{du} = 2u = 2(kX_i  - y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{d(u)}{dk} = \\dfrac{d(kX_i  - y_i)}{dk} = \\dfrac{d(kX_i)}{dk}  - \\dfrac{d(y_i)}{dk} = X_i - 0 = X_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\dfrac{d((kX_i  - y_i)^2)}{dk} = 2(kX_i  - y_i) X_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И собирая все вместе:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\dfrac{dJ(k)}{dk} = \\dfrac{1}{N}  \\sum_{i=1}^{N}2(kX_i  - y_i) X_i$\n",
    "\n",
    "$\\dfrac{dJ(k)}{dk} = \\dfrac{2}{N}  \\sum_{i=1}^{N}(kX_i  - y_i) X_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, как выглядит эта производная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_loss_and_der(X, y, same=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование производной для поиска минимума Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим, как мы можем использовать производную для решения нашей задачи. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*У нас есть функция ошибки $Loss(k)$. Нужно найти такое $k_m$, при котором $Loss(k_m)$ принимает минимальное значение.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, когда я обсуждал как найти значение минимума для данной функции вы уже знали решение этой задачи знакомое со школы. \n",
    "\n",
    "$J'(k) = \\dfrac{dJ(k)}{dk} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно вспомнить кто угол касательной в минимальной точке равно 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот метод называется методом наименьших квадратов (МНК)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно взять производную функции ошибки и приравнять ее к нулю и решить уравнение относительно k. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\dfrac{dJ(k)}{dk} =  \\dfrac{2}{N} \\sum_{i=1}^{N} (kX_i - y_i)X_i = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_a = analytical_solution(X, y)\n",
    "print(f\"Аналитически решенное k={k_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data_and_hyp(X, y, k_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Очень важно!**\n",
    "\n",
    "Посчитать коэффициент аналитически можно только в данном простом, учебном примере. Но в реальных примерах не всегда возможно решить это уравнение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Поэтому, познакомимся с таким алгоритмом как градиентный спуск. \n",
    "\n",
    "Данный алгоритм является одним самых распространенных алгоритмов в машинном обучении. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идею градиентной спуска мы обсуждали ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение производной в точке равно значению тангенса угла наклона касательной в данной точке или же показывает растет ли функция или убывает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим мы видим, что производная равна отрицательному значению. Это значит, что функция ошибки в окрестности данной точки убывает. То есть, если взять $k$ поменьше, то ошибка будет расти, а если взять $k$ немоного побольше, то ошибка будет убывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь допустим производная положительна. Это значит, что функция ошибки в окрестности данной точки возрастает. То есть, если взять $k$ побольше, то ошибка будет расти, а если поменьше, то ошибка будет убывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда наш алгоритм по поиску минимального значения можно описать следящим образом.\n",
    "\n",
    "Мы берем случайное значение $k$. Считаем значение производной для этого параметра. Если производная положительная, берем новое $k$ чуть меньше чем было, если производная отрицательная, то берем новое значение для $k$ чуть побольше. Это все повторяем до тех пор, пока нас не устроит значение ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единственный вопрос, а на какое значение менять $k$?\n",
    "\n",
    "Хотелось бы менять его на большое значение, когда $k$ мы далеко от минимума функции. И менять $k$ не сильно, когда мы близко к минимуму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте еще раз посмотрим на функцию и ее производную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_loss_and_der(X, y, der_value=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем дальше мы от минимума, тем больше (по модулю) значение производной. Так давайте и использовать значение производной, раз нам и так нужно будет ее считать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом сам алгоритм градиентного спуска можно описать следующим образом:\n",
    "\n",
    "* Выбираем случайное значение для $k$\n",
    "* Повторяем $iter$ раз:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_{new} = k - \\alpha \\cdot \\dfrac{d  J(k)}{dk}$,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k = k_{new}$,\n",
    "\n",
    "где $\\alpha$ это коэффициент, который мы выбреем. Он называется коэффициент обучения (learning rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha$ нам нужна, так как иногда производная может быть слишкой большой или слишком маленькой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте реализуем подсчет производной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для входных данных массива $X$, реального выходного значения $y$ и параметра $k$ необходимо реализовать подсчет производной. \n",
    "\n",
    "На входе:\n",
    "\n",
    "* Массив входных значений $X$;\n",
    "\n",
    "* Массив реальных выходных значений $y$;\n",
    "\n",
    "* Коэффициент $k$ функции $f(X)=kX$;\n",
    "\n",
    "\n",
    "На выходе:\n",
    "\n",
    "* На выходе значение производной функции ошибки $Loss'(k)$\n",
    "\n",
    "Формула производной функции ошибки:\n",
    "\n",
    "$Loss'(k) = \\dfrac{2}{N} \\sum_{i=0}^{N}{(kX_i - y_i)X_i} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_function(X, y, k):\n",
    "    # С помощью f(X, k) мы находим массив предсказанных значений и вычитаем из него массив реальных выходных значений\n",
    "    # Эту разность мы поэлементно умножаем на массив Х\n",
    "    # С помощью функции np.mean мы получаем среднее значение массива.\n",
    "    # np.mean(X) эквивалентной np.sum(X)/len(X)\n",
    "    \n",
    "    derivative = 2*np.mean((f(X, k) - y) * X)\n",
    "    return derivative   \n",
    "\n",
    "k = 1\n",
    "print(derivative_function(X, y, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте реализуем градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для входных данных массива $X$, реального выходного значения $y$, начального значения $k_{init}$, значения параметра $\\alpha$ необходимо реализовать градиентный спуск. \n",
    "\n",
    "На входе:\n",
    "\n",
    "* Массив входных значений $X$;\n",
    "\n",
    "* Массив реальных выходных значений $y$;\n",
    "\n",
    "* Начальный коэффициент функции $k_{init}$;\n",
    "\n",
    "* Коэффициент обучения $\\alpha$;\n",
    "\n",
    "* Количество итераций алгоритма $iter$;\n",
    "\n",
    "На выходе:\n",
    "\n",
    "* На выходе значение коэффициента $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм градиентного спуска:\n",
    "\n",
    "* Выбираем случайное значение для $k$\n",
    "* Повторяем $iter$ раз:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_{new} = k - \\alpha \\cdot \\dfrac{d  J(k)}{dk}$,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k = k_{new}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, k_init, alpha, iters):\n",
    "    \n",
    "    # инициализируем начальное значение\n",
    "    k = k_init\n",
    "    \n",
    "    # выполняем iters раз\n",
    "    for i in range(0, iters):\n",
    "        # считаем производную, умножаем ее на коэффициент обучение\n",
    "        # меняем коэффициент на значение производной умноженной на альфу\n",
    "        k = k - (alpha * derivative_function(X, y, k))\n",
    "        \n",
    "        # Можно заменить на \n",
    "        # k -= alpha * derivative_function(X, y, k)\n",
    "    # возвращаем посчитанное значение\n",
    "    return k\n",
    "\n",
    "k_init = 1.0\n",
    "alpha = 1\n",
    "iters = 100\n",
    "k_gd = gradient_descent(X, y, k_init, alpha, iters)\n",
    "\n",
    "print(f\"Значение после градиентного спуска k={k_gd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Аналитически решенное k={k_a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Значение функции ошибки после обучения {loss_function(X, y, k_gd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Значение функции ошибки для аналитического решения {loss_function(X, y, k_a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Разница функция ошибок {loss_function(X, y, k_a) - loss_function(X, y, k_gd)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как ведет себя алгоритм с различными параметрами $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем выбрать начальную точку, коэффициент обучения и количество итераций алгоритма градиентного спуска.\n",
    "\n",
    "Справа у нас значение функции ошибки и точки, полученные при градиентном спуске. \n",
    "\n",
    "Слева у нас полученная функция. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_gradient_descent(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличивая $\\alpha$ мы можем заметить что алгоритму требуется меньше итераций.\n",
    "\n",
    "Но есть интересный случай. Если мы увеличиваем значение коэффициента $\\alpha$, то наш алгоритм начинает расходиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Как это можно использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, дойдя до такого момента, вы можете спросить: это что мне нужно каждый раз производные считать, если я хочу просто линейную регрессию посчитать?\n",
    "\n",
    "Ответ: нет.\n",
    "\n",
    "Конечно существуют готовые решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть замечательная библиотека sklearn. Используя ее, мы можем в 3 строчки посчитать линейную регрессию. Сделаем это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# загружаем линейную регрессию из библиотеки sklearn\n",
    "# в ней реализован класс LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# создаем объект линейной регрессии. не обращайте внимание на атрибут fit_intercept\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# обучаем нашу модель. То есть, запускаем алгоритм, который находит оптимальные параметры. \n",
    "# нужно будет немного поменять shape входных данных\n",
    "lr.fit(X.reshape(-1, 1), y.reshape(-1, 1))\n",
    "\n",
    "# И получаем значение коэффициента\n",
    "k_sklearn = lr.coef_[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\" Абсолютная разница между коэффициентами посчитанным нами и посчитанным sklean'ом {abs(k_gd - k_sklearn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на наш конечный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data_and_hyp(X, y, k_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Немного усложним пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что функция выходит из 0 по оси $Y$. Но кажется что она должна выходить из 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве гипотезы мы использовали функцияю вида $f(X) = kX$.\n",
    "\n",
    "Такой вид фукнции всегда будет выходить из 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я называл функцию $f(X) = kX$ линейной функцией. Но многие из вас могли заметить, что это не совсем линейная функция. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная функцию на самом деле выглядит так:\n",
    "\n",
    "$f(X) = kX + b$.\n",
    "\n",
    "Давайте на нее посмотрим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "choose_slope_with_bias(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте изменим гипотезу и теперь будем использовать \"настоящую\" линейную функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепишем функцию ошибки:\n",
    "\n",
    "$\\hat{y} = f(X) = kX + b$. То есть, $\\hat{y}$ является предсказанными нами значениями для $X$. \n",
    "А настоящие значения будут равны $y$. \n",
    "\n",
    "Тогда ошибка на одном примере равна $error_i(k, b)$ на i-ом примере будет равна:\n",
    "\n",
    "$error_i(k, b) = (\\hat{y_i} - y_i)^2 = ((kX_i + b) - y_i)^2$.\n",
    "\n",
    "А на всех примерах:\n",
    "\n",
    "$Loss(k, b) = \\dfrac{1}{N}\\sum_{i=0}^{N}{(\\hat{y_i} - y_i)^2}= \\dfrac{1}{N} \\sum_{i=0}^{N}{((kX_i + b) - y_i)^2} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что теперь у нас ошибка зависит не только от $k$, но и от $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как теперь выглядит функция ошибки. \n",
    "\n",
    "Но так как она теперь зависит от 2-х параметров, то теперь для ее визуализации нам нужно 3D пространство.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_linear_loss_in_3d(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но проще всего нам просто смотреть на функцию сверху.\n",
    "\n",
    "График ниже, это как бы вид сверху на 3D функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_linear_loss_in_3d_up(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо. \n",
    "\n",
    "У нас есть функция ошибки. Но теперь она от двух параметров. Что нам теперь делать?\n",
    "\n",
    "Алгоритм, который мы использовали, называется градиентный спуск. \n",
    "\n",
    "Он так называется не спроста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте введем понятие градиента.\n",
    "\n",
    "Градиент функции $\\phi(x_0, x_1, \\ldots x_N)$ от $N$ переменных это $N$ значений: \n",
    "\n",
    "$\\dfrac{\\delta \\phi(x_0, x_1, \\ldots x_N)}{\\delta x_0}, \\dfrac{\\delta \\phi(x_0, x_1, \\ldots x_N)}{\\delta x_1}, \\ldots \\dfrac{\\delta \\phi(x_0, x_1, \\ldots x_N)}{\\delta x_N}$\n",
    "\n",
    "Обозначается как $grad (\\phi)$ или  $\\nabla \\phi$ (читается как набла фи)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, градиент функции $\\phi(x, y)$  от двух переменных это:\n",
    "\n",
    "$grad (\\phi) = \\nabla \\phi = \\left[\\dfrac{\\delta \\phi(x, y)}{\\delta x}; \\dfrac{\\delta \\phi(x, y)}{\\delta y} \\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти значения можно считать координатами вектора (в декартовой системе координат) и их можно записать как: \n",
    "\n",
    "$grad (\\phi) = \\nabla \\phi = \\dfrac{\\delta \\phi(x, y)}{\\delta x} \\cdot \\overleftarrow{i} + \\dfrac{\\delta \\phi(x, y)}{\\delta y} \\cdot \\overleftarrow{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{\\delta \\phi(x, y)}{\\delta x}$ - это *частная* производная по $x$.\n",
    "\n",
    "Соответственно, $\\dfrac{\\delta \\phi(x, y)}{\\delta y}$ - это частная производная по $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что это значит? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частная производная - это производная по какой-либо переменной, например $x$, где остальные переменные мы считаем константой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример вычисления градиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi(x, y) = (1.5x + 2.5)^2 + 2.5y^2 + 0.5$\n",
    "\n",
    "$\\dfrac{\\delta \\phi(x, y)}{\\delta x} =\n",
    "\\dfrac{\\delta (1.5x + 2.5)^2 }{\\delta x} +\n",
    "\\dfrac{\\delta (2.5y^2)  }{\\delta x} +\n",
    "\\dfrac{\\delta (0.5) }{\\delta x}\n",
    "= 1.5 \\cdot 2(1.5x + 2.5) + 0 + 0= 4.5x + 7.5$\n",
    " \n",
    "\n",
    "$\\dfrac{\\delta \\phi(x, y)}{\\delta y} =\n",
    "\\dfrac{\\delta (x + 1.5)^2 }{\\delta y} +\n",
    "\\dfrac{\\delta (2.5y^2)  }{\\delta y} +\n",
    "\\dfrac{\\delta (0.5) }{\\delta y}\n",
    "= 0 + 2 \\cdot 2.5y + 0= 5y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте визуализируем  функцию $\\phi(x, y) = (x + 1.5)^2 + 2.5y^2 + 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_func_in_3d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим ее сверху."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d_func_with_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посчитаем на ее градиент (подробно он был рассчитан выше)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\phi(x, y) = (1.5x + 2.5)^2 + 2.5y^2 + 0.5$\n",
    "\n",
    "$\\dfrac{\\delta \\phi(x, y)}{\\delta x} = 4.5x + 7.5$\n",
    "\n",
    "$\\dfrac{\\delta \\phi(x, y)}{\\delta y} = 5y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда сам градиент из точки (0.4; 0.8) это вектор с началом из этой точки, который направленный в сторону **от** минимума."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d_func_with_grad(x0=-0.4, y0=0.8, pos_neg_grad='positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И если мы возьмем отрицательный градиент (антиградиент), то этот вектор будет направлен **в** сторону минимума."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d_func_with_grad(x0=-0.4, y0=0.8, pos_neg_grad='negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже можно посмотреть значения градиента и антиградиента для разных точек. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут наглядно можно увидеть, что, что бы попасть в минимум нужно обязательно уменьшать градиент коэффициентом $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_3d_func_with_grad_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиент функции ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зная все это, мы можем найти градиент нашей функции ошибки и использовать его для поиска минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша функция ошибки зависит от двух параметров $k, b$:\n",
    "\n",
    "$Loss(k, b) = \\dfrac{1}{N}\\sum_{i=1}^{N}{(\\hat{y_i} - y_i)^2}= \\dfrac{1}{N} \\sum_{i=1}^{N}{( (k X + b)  - y_i)^2}$\n",
    "\n",
    "Тогда градиент функции ошибки будет следующий:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{\\delta  Loss(k, b)}{\\delta b} = \\dfrac{1}{N} \\sum_{i=1}^{N} 2((k X_i + b)  - y_i)\\dfrac{\\delta ((k X_i + b)  - y_i) }{\\delta b}$ \n",
    "\n",
    "$\\dfrac{\\delta  Loss(k, b)}{\\delta b} = \\dfrac{2}{N} \\sum_{i=1}^{N} ((k X_i + b)  - y_i)( 0 + 1 + 0)$ \n",
    "\n",
    "$\\dfrac{\\delta  Loss(k, b)}{\\delta b} = \\dfrac{2}{N} \\sum_{i=1}^{N} ((k X_i + b)  - y_i)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{\\delta Loss(k, b)}{\\delta k} = \\dfrac{1}{N} \\sum_{i=1}^{N} 2((k X_i + b)  - y_i)\\dfrac{\\delta ((k X_i + b)  - y_i) }{\\delta k}$ \n",
    "\n",
    "$\\dfrac{\\delta  Loss(k, b)}{\\delta k} = \\dfrac{2}{N} \\sum_{i=1}^{N} ((k X_i + b)  - y_i)( X_i + 0 + 0)$ \n",
    "\n",
    "$\\dfrac{\\delta  Loss(k, b)}{\\delta k} = \\dfrac{2}{N}\\sum_{i=1}^{N} ((k X_i + b)  - y_i)X_i$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla Loss(k, b) = \\left[\\dfrac{2}{N} \\sum_{i=1}^{N} ((k X_i + b)  - y_i)X_i ; \\dfrac{2}{N}\\sum_{i=1}^{N} ((k X_i + b)  - y_i) \\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда алгоритм градиентного спуска теперь можно переписать как:\n",
    "\n",
    "* Выбираем случайное значение для $k$ и $b$\n",
    "* Повторяем $iter$ раз:\n",
    "\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $b_{new} = b  - \\alpha \\cdot \\dfrac{\\delta J(k, b)}{\\delta b} $ \n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $k_{new} = k - \\alpha \\cdot \\dfrac{\\delta J(k, b)}{\\delta k} $ \n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $b = b_{new}$, \n",
    "    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  $k = k_{new}$\n",
    "    \n",
    "\n",
    "где $\\alpha$ это коэффициент обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alpha=0.75 интересный случай\n",
    "\n",
    "k_gd, b_gd = plot_gradient_descent_in_3d(X, y, iters=300, alpha=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Значение функции ошибки после обучения {linearn_loss_function(X, y, k_gd, b_gd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_gd, b_gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data_and_hyp_with_bias(X, y, k_gd, b_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим как наш градиентный спуск работал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь посмотрим, как высчитывался градиент и менялась целевая функция на разных итерациях градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_gradient_descent_in_3d_interactive(X, y, iters=200, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приминение sklearn для решения задачи линейной регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# создаем объект линейной регрессии. \n",
    "lr = LinearRegression()\n",
    "\n",
    "# до этого мы создавали его так LinearRegression(fit_intercept=False)\n",
    "# этот параметр отвечал за вид функции \n",
    "# при fit_intercept=False используется функция f(x) = kx\n",
    "# если не указывать этот параметр, то используется функция f(x) = kx + b\n",
    "\n",
    "# обучаем нашу модель\n",
    "lr.fit(X.reshape(-1, 1), y.reshape(-1, 1))\n",
    "\n",
    "# И получаем значение коэффициентов\n",
    "k_sklearn = lr.coef_[0, 0]\n",
    "b_sklearn= lr.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Значения коэффициентов k={k_sklearn} и b={b_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Значение функции ошибки после обучения {linearn_loss_function(X, y, k_sklearn, b_sklearn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Значение коэффициентов после градиентного спуска k={k_gd}, b={b_gd},  \")\n",
    "print(f\"Значение коэффициентов посчитанное с помощью skealrn k={k_sklearn}, b={b_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Абсолютная разница между параметрами k: {abs(k_gd - k_sklearn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Абсолютная разница между параметрами b: {abs(b_gd - b_sklearn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(f\"Абсолютная разница ошибок {linearn_loss_function(X, y, k_gd, b_gd) - linearn_loss_function(X, y, k_sklearn, b_sklearn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чему мы сегодня научились"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Линейная функция\n",
    "* Функция потерь\n",
    "* Производная\n",
    "* Градиентный спуск\n",
    "* Применение регрессии из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Что если наша целевая функция зависит от нескольких параметров?\n",
    "\n",
    "* Что если нам нужно создать \"кривую\" функцию?\n",
    "\n",
    "* Что такое нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не строгое доказательство положительной производной при росте функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим в окрестности точки $x_1$ функция возрастает:\n",
    "\n",
    "$x_2 > x_1$,\n",
    "\n",
    "$f(x_2) > f(x_1)$.\n",
    "\n",
    "тогда если мы возьмем положительный $\\Delta$ то значение производной будет положительной\n",
    "\n",
    "$f(x_0 + \\Delta x) > f(x_0) $,\n",
    "\n",
    "$f(x_0 + \\Delta x) - f(x_0) > 0$,\n",
    "\n",
    "$\\Delta x > 0$.\n",
    "\n",
    "Следовательно $\\dfrac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x} > 0$.\n",
    "\n",
    "Если мы возьмем отрицательный $\\Delta$ то значение производной также будет положительной:\n",
    "\n",
    "$ f(x_0 - \\Delta x) < f(x_0)$,\n",
    "\n",
    "$f(x_0 + \\Delta x) - f(x_0) < 0$,\n",
    "\n",
    "$\\Delta x < 0$,\n",
    "\n",
    "Следовательно $\\dfrac{f(x_0 - \\Delta x) - f(x_0)}{-\\Delta x} > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в окрестности точки $x_1$ функция убывает, то производная будет отрицательная.\n",
    "\n",
    "*Ответственность за доказательство этого утверждения я передаю читателю данного ноутбука*."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {
    "03fc38044a514408b9de41fa70bf122f": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "19b7b5447a594ae1a20b764ac13118cc": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "28304c0dfbab44f5a851af84bf5947d3": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "3f700e837fd046ddb14ee8776ac8bc04": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "50d7c06a111e43c1860a5b10a576bfd3": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "a74e340d7bb24d9bb020ad7dd982e764": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "d5593dc80c0445c7ae64c7da2d37f72f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "d644b9b546b849c6b17acb3be1f1952b": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "eac5158d5b6c45c4afa73b58b8b0e58a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f4cec2743faf43ad9b8e7c828c6ee76a": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
